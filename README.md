# linear_mem_attention_torch
Implements https://arxiv.org/abs/2112.05682 to get linear memory cost on attention
